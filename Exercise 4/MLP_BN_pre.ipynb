{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_iYcla4kCX67"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "seed=5184\n",
        "np.random.seed(5184)\n",
        "tf.random.set_seed(5184)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgna3kY6CX67",
        "outputId": "46d2e0c4-8fd0-4f91-daa6-b49b05f35f2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "tf.executing_eagerly()\n",
        "tf.config.list_physical_devices('GPU')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "JodgHy9nCX68",
        "outputId": "3e720be4-21da-4381-fc68-016014ed4de6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data() # Load MNIST or FMNIST\n",
        "assert X_train.shape == (60000, 28, 28)\n",
        "assert X_test.shape == (10000, 28, 28)\n",
        "assert y_train.shape == (60000,)\n",
        "assert y_test.shape == (10000,)\n",
        "\n",
        "\n",
        "# Display randomly selected data\n",
        "indices = list(np.random.randint(X_train.shape[0],size=3))\n",
        "for i in range(3):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(X_train[indices[i]].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.title(\"Index {} Class {}\".format(indices[i], y_train[indices[i]]))\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIRI-uLoCX69",
        "outputId": "325cbb91-1137-4db0-9a88-2cd71c01f982"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of training set is 50000 samples\n",
            "every train example is 28 by 28\n",
            "size of validation set is 10000 samples\n",
            "every validation example is 28 by 28\n",
            "size of training set is 50000 samples\n",
            "every train example has 784 features\n",
            "size of validation set is 10000 samples\n",
            "every validation example has 784 features\n"
          ]
        }
      ],
      "source": [
        "# Split train dataset into train and validation\n",
        "X_val = X_train[50000:60000]\n",
        "X_train = X_train[0:50000]\n",
        "y_val = y_train[50000:60000]\n",
        "y_train = y_train[0:50000]\n",
        "\n",
        "print(\"size of training set is\", str(X_train.shape[0]), \"samples\")\n",
        "print(\"every train example is\", str(X_train.shape[1]), \"by\", str(X_train.shape[2]))\n",
        "\n",
        "print(\"size of validation set is\", str(X_val.shape[0]), \"samples\")\n",
        "print(\"every validation example is\", str(X_val.shape[1]), \"by\", str(X_val.shape[2]))\n",
        "\n",
        "X_train = X_train.reshape(50000, 28*28)\n",
        "X_val = X_val.reshape(10000, 28*28)\n",
        "X_test = X_test.reshape(10000, 28*28)\n",
        "\n",
        "print(\"size of training set is\", str(X_train.shape[0]), \"samples\")\n",
        "print(\"every train example has\", str(X_train.shape[1]), \"features\")\n",
        "\n",
        "print(\"size of validation set is\", str(X_val.shape[0]), \"samples\")\n",
        "print(\"every validation example has\", str(X_val.shape[1]), \"features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDyZ8bZjCX69",
        "outputId": "f27669a6-2b89-4172-8d66-5ce233b768d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "X_train = X_train/255.0\n",
        "X_val = X_val/255.0\n",
        "X_test = X_test/255.0\n",
        "# X_train[0]\n",
        "np.max(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lIIy313CX69",
        "outputId": "cf15f559-99f0-4c8c-fc15-071ba44d5ea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10000], shape=(1,), dtype=int32)\n",
            "tf.Tensor([10000    10], shape=(2,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "size_input = X_train.shape[1]\n",
        "size_hidden1 = 128\n",
        "size_hidden2 = 128\n",
        "size_hidden3 = 128\n",
        "size_output = 10\n",
        "\n",
        "batch_size=128\n",
        "lr=0.1\n",
        "\n",
        "number_of_train_examples = X_train.shape[0]\n",
        "number_of_test_examples = X_test.shape[0]\n",
        "\n",
        "print(tf.shape(y_val))\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10) # Other function is tf.one_hot(y_train,depth=10)\n",
        "y_val = tf.keras.utils.to_categorical(y_val, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "print(tf.shape(y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "obN7WPLpCX69"
      },
      "outputs": [],
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden1: int, size of the 1st hidden layer\n",
        "    size_hidden2: int, size of the 2nd hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden1, self.size_hidden2, self.size_hidden3, self.size_output, self.device =\\\n",
        "    size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device\n",
        "\n",
        "    self.initial=tf.keras.initializers.he_normal(seed=seed)\n",
        "    \n",
        "    # Initialize weights between input mapping and a layer g(f(x)) = layer\n",
        "    self.W1 = tf.Variable(self.initial([self.size_input, self.size_hidden1])) # Xavier(Fan-in fan-out) and Orthogonal\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b1 = tf.Variable(tf.zeros([1, self.size_hidden1])) # 0 or constant(0.01)\n",
        "    \n",
        "    # Initialize weights between input layer and 1st hidden layer\n",
        "    self.W2 = tf.Variable(self.initial([self.size_hidden1, self.size_hidden2]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b2 = tf.Variable(tf.zeros([1, self.size_hidden2]))\n",
        "    \n",
        "    # Initialize weights between 1st hidden layer and 2nd hidden layer\n",
        "    self.W3 = tf.Variable(self.initial([self.size_hidden2, self.size_hidden3]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b3 = tf.Variable(tf.zeros([1, self.size_hidden3]))\n",
        "    \n",
        "     # Initialize weights between 2nd hidden layer and output layer\n",
        "    self.W4 = tf.Variable(self.initial([self.size_hidden3, self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b4 = tf.Variable(tf.zeros([1, self.size_output]))\n",
        "\n",
        "    self.gamma1=tf.Variable(tf.ones([1, self.size_hidden1]))\n",
        "    self.beta1=tf.Variable(tf.zeros([1, self.size_hidden1]))\n",
        "\n",
        "    self.gamma2=tf.Variable(tf.ones([1, self.size_hidden2]))\n",
        "    self.beta2=tf.Variable(tf.zeros([1, self.size_hidden2]))\n",
        "\n",
        "    self.gamma3=tf.Variable(tf.ones([1, self.size_hidden3]))\n",
        "    self.beta3=tf.Variable(tf.zeros([1, self.size_hidden3]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.W4, self.b1, self.b2, self.b3, self.b4, self.gamma1, self.beta1, self.gamma2, self.beta2, self.gamma3, self.beta3]\n",
        "\n",
        "    self.mean1=tf.Variable(tf.zeros([1, self.size_hidden1]))\n",
        "    self.var1=tf.Variable(tf.ones([1, self.size_hidden1]))\n",
        "    self.mean2=tf.Variable(tf.zeros([1, self.size_hidden2]))\n",
        "    self.var2=tf.Variable(tf.ones([1, self.size_hidden2]))\n",
        "    self.mean3=tf.Variable(tf.zeros([1, self.size_hidden3]))\n",
        "    self.var3=tf.Variable(tf.ones([1, self.size_hidden3]))\n",
        "\n",
        "    self.variables_untraining = [self.mean1, self.var1, self.mean2, self.var2, self.mean3, self.var3]\n",
        "\n",
        "    self.epsilon=0.001\n",
        "\n",
        "    #self.untrain_variables=[]\n",
        "  \n",
        "  def forward(self, X, training):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X, training)\n",
        "    else:\n",
        "      self.y = self.compute_output(X, training)\n",
        "      \n",
        "    return self.y\n",
        "\n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    #y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_true_tf = tf.cast(y_true, dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    loss_x = cce(y_true_tf, y_pred_tf)\n",
        "    # Use keras or tf_softmax, both should work for any given model\n",
        "    #loss_x = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred_tf, labels=y_true_tf))\n",
        "    \n",
        "    return loss_x\n",
        "\n",
        "  def backward(self, X_train, y_train, opti):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = opti\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "        \n",
        "      predicted = self.forward(X_train, True)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "        \n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "           \n",
        "  def compute_output(self, X, training):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    if training==True:\n",
        "      # Cast X to float32\n",
        "      X_tf = tf.cast(X, dtype=tf.float32)\n",
        "      #X_tf = X\n",
        "      \n",
        "      # Compute values in hidden layers\n",
        "      z1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "      mean1=tf.math.reduce_mean(z1, 0)\n",
        "      var1=tf.math.reduce_variance(z1, 0)\n",
        "      z1 = (z1-mean1)/tf.math.sqrt(var1+self.epsilon)*self.gamma1+self.beta1\n",
        "      h1 = tf.nn.relu(z1)\n",
        "      \n",
        "      z2 = tf.matmul(h1, self.W2) + self.b2\n",
        "      mean2=tf.math.reduce_mean(z2, 0)\n",
        "      var2=tf.math.reduce_variance(z2, 0)\n",
        "      z2 = (z2-mean2)/tf.math.sqrt(var2+self.epsilon)*self.gamma2+self.beta2\n",
        "      h2 = tf.nn.relu(z2)\n",
        "      \n",
        "      z3 = tf.matmul(h2, self.W3) + self.b3\n",
        "      mean3=tf.math.reduce_mean(z3, 0)\n",
        "      var3=tf.math.reduce_variance(z3, 0)\n",
        "      z3 = (z3-mean3)/tf.math.sqrt(var3+self.epsilon)*self.gamma3+self.beta3\n",
        "      h3 = tf.nn.relu(z3)\n",
        "\n",
        "      # Compute output\n",
        "      output = tf.matmul(h3, self.W4) + self.b4\n",
        "      \n",
        "      #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this \n",
        "      # Second add tf.Softmax(output) and then return this variable\n",
        "    elif training==False:\n",
        "      # Cast X to float32\n",
        "      X_tf = tf.cast(X, dtype=tf.float32)\n",
        "      #X_tf = X\n",
        "      \n",
        "      # Compute values in hidden layers\n",
        "      z1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "      mean1=self.mean1\n",
        "      var1=self.var1\n",
        "      z1 = (z1-mean1)/tf.math.sqrt(var1+self.epsilon)*self.gamma1+self.beta1\n",
        "      h1 = tf.nn.relu(z1)\n",
        "      \n",
        "      z2 = tf.matmul(h1, self.W2) + self.b2\n",
        "      mean2=self.mean2\n",
        "      var2=self.var2\n",
        "      z2 = (z2-mean2)/tf.math.sqrt(var2+self.epsilon)*self.gamma2+self.beta2\n",
        "      h2 = tf.nn.relu(z2)\n",
        "      \n",
        "      z3 = tf.matmul(h2, self.W3) + self.b3\n",
        "      mean3=self.mean3\n",
        "      var3=self.var3\n",
        "      z3 = (z3-mean3)/tf.math.sqrt(var3+self.epsilon)*self.gamma3+self.beta3\n",
        "      h3 = tf.nn.relu(z3)\n",
        "\n",
        "      # Compute output\n",
        "      output = tf.matmul(h3, self.W4) + self.b4\n",
        "\n",
        "    return (output)\n",
        "\n",
        "  def updateBN(self, X):\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #X_tf = X\n",
        "    \n",
        "    # Compute values in hidden layers\n",
        "    z1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    self.mean1=tf.math.reduce_mean(z1, 0)\n",
        "    self.var1=tf.math.reduce_variance(z1, 0)\n",
        "    z1 = (z1-self.mean1)/tf.math.sqrt(self.var1+self.epsilon)*self.gamma1+self.beta1\n",
        "    h1 = tf.nn.relu(z1)\n",
        "    \n",
        "    z2 = tf.matmul(h1, self.W2) + self.b2\n",
        "    self.mean2=tf.math.reduce_mean(z2, 0)\n",
        "    self.var2=tf.math.reduce_variance(z2, 0)\n",
        "    z2 = (z2-self.mean2)/tf.math.sqrt(self.var2+self.epsilon)*self.gamma2+self.beta2\n",
        "    h2 = tf.nn.relu(z2)\n",
        "    \n",
        "    z3 = tf.matmul(h2, self.W3) + self.b3\n",
        "    self.mean3=tf.math.reduce_mean(z3, 0)\n",
        "    self.var3=tf.math.reduce_variance(z3, 0)\n",
        "    z3 = (z3-self.mean3)/tf.math.sqrt(self.var3+self.epsilon)*self.gamma3+self.beta3\n",
        "    h3 = tf.nn.relu(z3)\n",
        "    \n",
        "    return\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "r6dPx97dnrln",
        "outputId": "079ac6d7-2d62-4c98-837b-5c5a8326a10c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: \n",
            " Validation Loss: 2.418447732925415, Validation Accuracy: 5.490000247955322\n",
            "Epoch 1:\n",
            " Loss: 0.36003512144088745, Accuracy: 87.06999969482422, Validation loss: 0.39720746874809265, Validation Accuracy: 85.5999984741211\n",
            "Epoch 2:\n",
            " Loss: 0.30672159790992737, Accuracy: 88.79600524902344, Validation loss: 0.36124852299690247, Validation Accuracy: 86.88999938964844\n",
            "Epoch 3:\n",
            " Loss: 0.2737051844596863, Accuracy: 89.98799896240234, Validation loss: 0.3430807590484619, Validation Accuracy: 87.47000122070312\n",
            "Epoch 4:\n",
            " Loss: 0.2554261386394501, Accuracy: 90.54000091552734, Validation loss: 0.34188583493232727, Validation Accuracy: 87.62000274658203\n",
            "Epoch 5:\n",
            " Loss: 0.231471985578537, Accuracy: 91.43999481201172, Validation loss: 0.3346148431301117, Validation Accuracy: 87.7699966430664\n",
            "Epoch 6:\n",
            " Loss: 0.21474480628967285, Accuracy: 92.16400146484375, Validation loss: 0.33158233761787415, Validation Accuracy: 88.0\n",
            "Epoch 7:\n",
            " Loss: 0.21028684079647064, Accuracy: 92.29800415039062, Validation loss: 0.3457857072353363, Validation Accuracy: 87.41999816894531\n",
            "Epoch 8:\n",
            " Loss: 0.19543154537677765, Accuracy: 92.84200286865234, Validation loss: 0.34726256132125854, Validation Accuracy: 87.87000274658203\n",
            "Epoch 9:\n",
            " Loss: 0.1965741366147995, Accuracy: 92.66799926757812, Validation loss: 0.3649391233921051, Validation Accuracy: 87.38999938964844\n",
            "Epoch 10:\n",
            " Loss: 0.19302159547805786, Accuracy: 92.94400024414062, Validation loss: 0.3766094744205475, Validation Accuracy: 87.62999725341797\n",
            "Epoch 11:\n",
            " Loss: 0.16828078031539917, Accuracy: 93.88399505615234, Validation loss: 0.3705143630504608, Validation Accuracy: 87.72000122070312\n",
            "\n",
            "Total time taken (in seconds): 130.91\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "NUM_EPOCHS = 11\n",
        "opti = tf.keras.optimizers.SGD(learning_rate = 0.1)\n",
        "\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
        "val_accuracy = tf.keras.metrics.CategoricalAccuracy(name='val_accuracy')\n",
        "\n",
        "train_loss.reset_states()\n",
        "train_accuracy.reset_states()\n",
        "val_loss.reset_states()\n",
        "val_accuracy.reset_states()\n",
        "\n",
        "mlp_on_default = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output)\n",
        "\n",
        "valid_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(X_val.shape[0])\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=seed).batch(batch_size)\n",
        "train_ds_all = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(X_train.shape[0])\n",
        "\n",
        "for inputs, outputs in valid_ds:\n",
        "  preds = mlp_on_default.forward(inputs, False)\n",
        "  val_loss(mlp_on_default.loss(preds,outputs))\n",
        "  val_accuracy(outputs, preds)\n",
        "\n",
        "print(\n",
        "  f'Epoch {0}: \\n '\n",
        "  f'Validation Loss: {val_loss.result()}, '\n",
        "  f'Validation Accuracy: {val_accuracy.result() * 100}'\n",
        ")\n",
        "plt.plot(0, val_accuracy.result(), 'ro-',label=\"Validate accuracy\")\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  val_loss.reset_states()\n",
        "  val_accuracy.reset_states()\n",
        "\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*seed).batch(batch_size)\n",
        "  \n",
        "  for inputs, outputs in train_ds:\n",
        "    mlp_on_default.backward(inputs, outputs,opti)\n",
        "\n",
        "  \n",
        "  for inputs, outputs in train_ds_all:\n",
        "    mlp_on_default.updateBN(inputs)\n",
        "\n",
        "  for inputs, outputs in train_ds_all:\n",
        "    preds = mlp_on_default.forward(inputs, False)\n",
        "    train_loss(mlp_on_default.loss(preds,outputs))\n",
        "    train_accuracy(outputs, preds)\n",
        "\n",
        "  for inputs, outputs in valid_ds:\n",
        "    preds = mlp_on_default.forward(inputs, False)\n",
        "    val_loss(mlp_on_default.loss(preds,outputs))\n",
        "    val_accuracy(outputs, preds)\n",
        "  \n",
        "  print(\n",
        "    f'Epoch {epoch + 1}:\\n '\n",
        "    f'Loss: {train_loss.result()}, '\n",
        "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
        "    f'Validation loss: {val_loss.result()}, '\n",
        "    f'Validation Accuracy: {val_accuracy.result() * 100}'\n",
        "  )\n",
        "  plt.plot(epoch + 1, train_accuracy.result(), 'go-',label=\"Train accuracy\")\n",
        "  plt.plot(epoch + 1, val_accuracy.result(), 'ro-',label=\"Validate accuracy\")\n",
        "\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObXcavjsnrlp",
        "outputId": "0bb9ab7d-c880-488b-e680-3d3f257881c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.38482609391212463, Test Accuracy: 87.91000366210938\n"
          ]
        }
      ],
      "source": [
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
        "\n",
        "test_loss.reset_states()\n",
        "test_accuracy.reset_states()\n",
        "\n",
        "train_ds_all = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(X_train.shape[0])\n",
        "for inputs, outputs in train_ds_all:\n",
        "  mlp_on_default.updateBN(inputs)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(X_test.shape[0])\n",
        "\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_default.forward(inputs,False)\n",
        "  test_loss(mlp_on_default.loss(preds,outputs))\n",
        "  test_accuracy(outputs, preds)\n",
        "\n",
        "print(\n",
        "  f'Test Loss: {test_loss.result()}, '\n",
        "  f'Test Accuracy: {test_accuracy.result() * 100}'\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "MLP_BN_pre.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}