{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_iYcla4kCX67"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "seed=1245\n",
        "np.random.seed(1245)\n",
        "tf.random.set_seed(1245)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgna3kY6CX67",
        "outputId": "36ab0499-329b-41a9-f77b-9845744bd75d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "tf.executing_eagerly()\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "JodgHy9nCX68",
        "outputId": "0985b3d5-fb86-4845-c92c-195510a1d05d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data() # Load MNIST or FMNIST\n",
        "assert X_train.shape == (60000, 28, 28)\n",
        "assert X_test.shape == (10000, 28, 28)\n",
        "assert y_train.shape == (60000,)\n",
        "assert y_test.shape == (10000,)\n",
        "\n",
        "\n",
        "indices = list(np.random.randint(X_train.shape[0],size=3))\n",
        "for i in range(3):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(X_train[indices[i]].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.title(\"Index {} Class {}\".format(indices[i], y_train[indices[i]]))\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIRI-uLoCX69",
        "outputId": "da621572-a02b-4ffe-f783-41de14bdb17a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of training set is 50000 samples\n",
            "every train example is 28 by 28\n",
            "size of validation set is 10000 samples\n",
            "every validation example is 28 by 28\n",
            "size of training set is 50000 samples\n",
            "every train example has 784 features\n",
            "size of validation set is 10000 samples\n",
            "every validation example has 784 features\n"
          ]
        }
      ],
      "source": [
        "# Split train dataset into train and validation\n",
        "X_val = X_train[50000:60000]\n",
        "X_train = X_train[0:50000]\n",
        "y_val = y_train[50000:60000]\n",
        "y_train = y_train[0:50000]\n",
        "\n",
        "print(\"size of training set is\", str(X_train.shape[0]), \"samples\")\n",
        "print(\"every train example is\", str(X_train.shape[1]), \"by\", str(X_train.shape[2]))\n",
        "\n",
        "print(\"size of validation set is\", str(X_val.shape[0]), \"samples\")\n",
        "print(\"every validation example is\", str(X_val.shape[1]), \"by\", str(X_val.shape[2]))\n",
        "\n",
        "X_train = X_train.reshape(50000, 28*28)\n",
        "X_val = X_val.reshape(10000, 28*28)\n",
        "X_test = X_test.reshape(10000, 28*28)\n",
        "\n",
        "print(\"size of training set is\", str(X_train.shape[0]), \"samples\")\n",
        "print(\"every train example has\", str(X_train.shape[1]), \"features\")\n",
        "\n",
        "print(\"size of validation set is\", str(X_val.shape[0]), \"samples\")\n",
        "print(\"every validation example has\", str(X_val.shape[1]), \"features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDyZ8bZjCX69",
        "outputId": "0e8fb625-e12d-436a-fb88-6d03913f3584"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "#Normalize Data\n",
        "\n",
        "X_train = X_train/255.0\n",
        "X_val = X_val/255.0\n",
        "X_test = X_test/255.0\n",
        "# X_train[0]\n",
        "np.max(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lIIy313CX69",
        "outputId": "620f7552-baef-4ccf-9fec-687164774eda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10000], shape=(1,), dtype=int32)\n",
            "tf.Tensor([10000    10], shape=(2,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "size_input = X_train.shape[1]\n",
        "size_hidden1 = 128\n",
        "size_hidden2 = 128\n",
        "size_hidden3 = 128\n",
        "size_output = 10\n",
        "\n",
        "batch_size=128\n",
        "lr=0.1\n",
        "\n",
        "number_of_train_examples = X_train.shape[0]\n",
        "number_of_test_examples = X_test.shape[0]\n",
        "\n",
        "print(tf.shape(y_val))\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10) # Other function is tf.one_hot(y_train,depth=10)\n",
        "y_val = tf.keras.utils.to_categorical(y_val, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "print(tf.shape(y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "obN7WPLpCX69"
      },
      "outputs": [],
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device=None):\n",
        "    self.size_input, self.size_hidden1, self.size_hidden2, self.size_hidden3, self.size_output, self.device =\\\n",
        "    size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device\n",
        "\n",
        "    self.initial=tf.keras.initializers.he_normal(seed=seed)\n",
        "    \n",
        "    # Initialize weights between input mapping and a layer g(f(x)) = layer\n",
        "    self.W1 = tf.Variable(self.initial([self.size_input, self.size_hidden1])) # Xavier(Fan-in fan-out) and Orthogonal\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b1 = tf.Variable(tf.zeros([1, self.size_hidden1])) # 0 or constant(0.01)\n",
        "    \n",
        "    # Initialize weights between input layer and 1st hidden layer\n",
        "    self.W2 = tf.Variable(self.initial([self.size_hidden1, self.size_hidden2]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b2 = tf.Variable(tf.zeros([1, self.size_hidden2]))\n",
        "    \n",
        "    # Initialize weights between 1st hidden layer and 2nd hidden layer\n",
        "    self.W3 = tf.Variable(self.initial([self.size_hidden2, self.size_hidden3]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b3 = tf.Variable(tf.zeros([1, self.size_hidden3]))\n",
        "    \n",
        "     # Initialize weights between 2nd hidden layer and output layer\n",
        "    self.W4 = tf.Variable(self.initial([self.size_hidden3, self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b4 = tf.Variable(tf.zeros([1, self.size_output]))\n",
        "\n",
        "    self.gamma1=tf.Variable(tf.ones([1, self.size_hidden1]))\n",
        "    self.beta1=tf.Variable(tf.zeros([1, self.size_hidden1]))\n",
        "\n",
        "    self.gamma2=tf.Variable(tf.ones([1, self.size_hidden2]))\n",
        "    self.beta2=tf.Variable(tf.zeros([1, self.size_hidden2]))\n",
        "\n",
        "    self.gamma3=tf.Variable(tf.ones([1, self.size_hidden3]))\n",
        "    self.beta3=tf.Variable(tf.zeros([1, self.size_hidden3]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.W4, self.b1, self.b2, self.b3, self.b4, self.gamma1, self.beta1, self.gamma2, self.beta2, self.gamma3, self.beta3]\n",
        "\n",
        "    self.mean1=tf.Variable(tf.zeros([1, self.size_hidden1]))\n",
        "    self.var1=tf.Variable(tf.ones([1, self.size_hidden1]))\n",
        "    self.mean2=tf.Variable(tf.zeros([1, self.size_hidden2]))\n",
        "    self.var2=tf.Variable(tf.ones([1, self.size_hidden2]))\n",
        "    self.mean3=tf.Variable(tf.zeros([1, self.size_hidden3]))\n",
        "    self.var3=tf.Variable(tf.ones([1, self.size_hidden3]))\n",
        "\n",
        "    self.variables_untraining = [self.mean1, self.var1, self.mean2, self.var2, self.mean3, self.var3]\n",
        "\n",
        "    self.epsilon=0.001\n",
        "\n",
        "    #self.untrain_variables=[]\n",
        "  \n",
        "  def forward(self, X, training):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X, training)\n",
        "    else:\n",
        "      self.y = self.compute_output(X, training)\n",
        "      \n",
        "    return self.y\n",
        "\n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    #y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_true_tf = tf.cast(y_true, dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    loss_x = cce(y_true_tf, y_pred_tf)\n",
        "    \n",
        "    return loss_x\n",
        "\n",
        "  def backward(self, X_train, y_train, opti):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = opti\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "        \n",
        "      predicted = self.forward(X_train, True)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "        \n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "           \n",
        "  def compute_output(self, X, training):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    if training==True:\n",
        "      # Cast X to float32\n",
        "      X_tf = tf.cast(X, dtype=tf.float32)\n",
        "      #X_tf = X\n",
        "      \n",
        "      # Compute values in hidden layers\n",
        "      z1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "      h1 = tf.nn.relu(z1)\n",
        "      mean1=tf.math.reduce_mean(h1, 0)\n",
        "      var1=tf.math.reduce_variance(h1, 0)\n",
        "      h1 = (h1-mean1)/tf.math.sqrt(var1+self.epsilon)*self.gamma1+self.beta1\n",
        "      \n",
        "      z2 = tf.matmul(h1, self.W2) + self.b2\n",
        "      h2 = tf.nn.relu(z2)\n",
        "      mean2=tf.math.reduce_mean(h2, 0)\n",
        "      var2=tf.math.reduce_variance(h2, 0)\n",
        "      h2 = (h2-mean2)/tf.math.sqrt(var2+self.epsilon)*self.gamma2+self.beta2\n",
        "      \n",
        "      z3 = tf.matmul(h2, self.W3) + self.b3\n",
        "      h3 = tf.nn.relu(z3)\n",
        "      mean3=tf.math.reduce_mean(h3, 0)\n",
        "      var3=tf.math.reduce_variance(h3, 0)\n",
        "      h3 = (h3-mean3)/tf.math.sqrt(var3+self.epsilon)*self.gamma3+self.beta3\n",
        "\n",
        "      # Compute output\n",
        "      output = tf.matmul(h3, self.W4) + self.b4\n",
        "      \n",
        "      #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this \n",
        "      # Second add tf.Softmax(output) and then return this variable\n",
        "    elif training==False:\n",
        "      # Cast X to float32\n",
        "      X_tf = tf.cast(X, dtype=tf.float32)\n",
        "      #X_tf = X\n",
        "      \n",
        "      # Compute values in hidden layers\n",
        "      z1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "      h1 = tf.nn.relu(z1)\n",
        "      mean1=self.mean1\n",
        "      var1=self.var1\n",
        "      h1 = (h1-mean1)/tf.math.sqrt(var1+self.epsilon)*self.gamma1+self.beta1\n",
        "      \n",
        "      z2 = tf.matmul(h1, self.W2) + self.b2\n",
        "      h2 = tf.nn.relu(z2)\n",
        "      mean2=self.mean2\n",
        "      var2=self.var2\n",
        "      h2 = (h2-mean2)/tf.math.sqrt(var2+self.epsilon)*self.gamma2+self.beta2\n",
        "      \n",
        "      z3 = tf.matmul(h2, self.W3) + self.b3\n",
        "      h3 = tf.nn.relu(z3)\n",
        "      mean3=self.mean3\n",
        "      var3=self.var3\n",
        "      h3 = (h3-mean3)/tf.math.sqrt(var3+self.epsilon)*self.gamma3+self.beta3\n",
        "\n",
        "      # Compute output\n",
        "      output = tf.matmul(h3, self.W4) + self.b4\n",
        "\n",
        "    return (output)\n",
        "\n",
        "  def BNLayer(self, X):\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #X_tf = X\n",
        "    \n",
        "    # Compute values in hidden layers\n",
        "    z1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    h1 = tf.nn.relu(z1)\n",
        "    self.mean1=tf.math.reduce_mean(h1, 0)\n",
        "    self.var1=tf.math.reduce_variance(h1, 0)\n",
        "    h1 = (h1-self.mean1)/tf.math.sqrt(self.var1+self.epsilon)*self.gamma1+self.beta1\n",
        "    \n",
        "    z2 = tf.matmul(h1, self.W2) + self.b2\n",
        "    h2 = tf.nn.relu(z2)\n",
        "    self.mean2=tf.math.reduce_mean(h2, 0)\n",
        "    self.var2=tf.math.reduce_variance(h2, 0)\n",
        "    h2 = (h2-self.mean2)/tf.math.sqrt(self.var2+self.epsilon)*self.gamma2+self.beta2\n",
        "    \n",
        "    z3 = tf.matmul(h2, self.W3) + self.b3\n",
        "    h3 = tf.nn.relu(z3)\n",
        "    self.mean3=tf.math.reduce_mean(h3, 0)\n",
        "    self.var3=tf.math.reduce_variance(h3, 0)\n",
        "    h3 = (h3-self.mean3)/tf.math.sqrt(self.var3+self.epsilon)*self.gamma3+self.beta3\n",
        "    \n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "id": "hJUoVOzAkARt",
        "outputId": "8196d456-5a11-423d-ae81-35e23e7102d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, \n",
            " Val Loss: 2.6522812843322754, Val Accuracy: 4.610000133514404\n",
            "Epoch 1, \n",
            "Loss: 0.3574874997138977, Accuracy: 87.20600128173828, Val loss: 0.3879603147506714, Val Accuracy: 86.22999572753906\n",
            "Epoch 2, \n",
            "Loss: 0.307399719953537, Accuracy: 88.71600341796875, Val loss: 0.3594907224178314, Val Accuracy: 86.97999572753906\n",
            "Epoch 3, \n",
            "Loss: 0.2919052243232727, Accuracy: 89.1780014038086, Val loss: 0.3552611768245697, Val Accuracy: 87.05999755859375\n",
            "Epoch 4, \n",
            "Loss: 0.2627684772014618, Accuracy: 90.27799987792969, Val loss: 0.33892884850502014, Val Accuracy: 87.79000091552734\n",
            "Epoch 5, \n",
            "Loss: 0.2508739233016968, Accuracy: 90.7280044555664, Val loss: 0.33590373396873474, Val Accuracy: 87.79000091552734\n",
            "Epoch 6, \n",
            "Loss: 0.23458921909332275, Accuracy: 91.3699951171875, Val loss: 0.3391087055206299, Val Accuracy: 87.63999938964844\n",
            "Epoch 7, \n",
            "Loss: 0.23351457715034485, Accuracy: 91.36000061035156, Val loss: 0.34540629386901855, Val Accuracy: 87.91000366210938\n",
            "Epoch 8, \n",
            "Loss: 0.21579261124134064, Accuracy: 92.03600311279297, Val loss: 0.3384791910648346, Val Accuracy: 88.12999725341797\n",
            "Epoch 9, \n",
            "Loss: 0.21360671520233154, Accuracy: 92.10600280761719, Val loss: 0.35339945554733276, Val Accuracy: 87.77999877929688\n",
            "Epoch 10, \n",
            "Loss: 0.20566628873348236, Accuracy: 92.45999908447266, Val loss: 0.352200448513031, Val Accuracy: 88.06999969482422\n",
            "\n",
            "Total time taken (in seconds): 119.92\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPiElEQVR4nO3df4xlZ13H8fdnd9vgFFwwuxLtdmf6x6JuqKYwadAaJRaTgtIaTEg3g6mGMAmxCEo0xTVQajaoGFr+qD8GRIg70tRKdKurq6k1EiOkU4otba1uyv4qYAfEVdxoW/r1j3tXZ7czO3e7994z88z7lUzu3Oee3uc53dn3nHvOndlUFZKk9W9T1wuQJA2HQZekRhh0SWqEQZekRhh0SWrElq4m3rZtW01NTXU1vSStSw888MBXq2r7co91FvSpqSkWFha6ml6S1qUkR1d6zFMuktQIgy5JjTDoktQIgy5JjTDoktQIgy5JYzL/8DxTt0+x6f2bmLp9ivmH54f6/AZdUidGHbe1OO/sPbMcPXmUojh68iiz98wOdX6DLmnsxhG3tTQvwN5793LqmVNnjJ165hR77907tDkMurQGbLSj1XHEbS3NC3Ds5LHzGn8hDLrU1/JL8bU0L4wnbmtpXoCdW3ee1/gLYdC15nQR1tZfiq+leWE8cVtL8wLsu2YfExdNnDE2cdEE+67ZN7Q5DLrWlK7C2vpL8bU0L4wnbmtpXoCZK2aYe+Mck1snCWFy6yRzb5xj5oqZoc1h0LWmdBXW1l+Kr6V5YTxxW0vzLp3/yLuO8Nz7nuPIu44Mfd7Oftui1r75h+fZe+9ejp08xs6tO9l3zb6Rf+F3FdadW3dy9OTzf4nduF6Kz94ze8Y3snEdrXYx72kzV8yMLaRrYd5x8Ah9jdtoF+q6Omps/aX4WppXo2PQ17CNeKGuq7B2HbdRvxRfcd6H4Mjt8Nz7e7czD41l2p75eZiagk2berfz4zlY6dSI99mgr2Eb8ULdzBUzHNp0I8c/vJlv3gLHP7yZQ5tuHEvgNlzc5udhdhaOHoWq3u3s7MaYu4tvJOPY56rq5OPVr351rSf7H9pfk7dNVm5JTd42Wfsf2j/yOXNLilt43kduycjnnrxtsva8ifriVuqb9G73vImavG1ytBPv3181MVHV+5LvfUxM9MZbnLfLuScnz5zz9Mfk5Gjn7XLuLv+ch7TPwEKt0FWDPoD9D+2viX0TZ0R1Yt/EyKPeWVSr6tMfeHt946Izv/C+cRH16Q+8fbQTd/UXfSPGLVl+3oz+gKGzubv8cx7SPhv0C9RVWDuLatXGi4xx85vYqI3hCN1z6AO4+tNH+cg9MHWyd9Fh6iR85J7e+Cj94O8c5JJnzhy75Jne+MgdW+Fc+Urjw7JzhXezrDS+3uftcu59+2DizAvQTEz0xketq7m7/HMexz6vVPpRf6ynI/TjL9u87HfW4y/bPNqJGziaOG+eQx//3JOTva+pycnxzNnl3F3+vz49/wXuM55yuTDPZZmwQW98lLp8SbwRI7PR4rZRrfP/1+cKenqPj9/09HQtLCx0Mvd5m5rqvcXobJOTcOTI6OY9/TanU0veujgxAXNzMDOG9ynPz8Pevb3TLDt39l4ajmNeSStK8kBVTS/3mOfQB9HV+b6ZmV68Jych6d2OK+an5z9yBJ57rndrzKU1zd/lMojTIeviaHVmxpBKGohBH5RhlbTGecpFkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQMFPcm1SR5PcjjJzcs8vjPJfUkeTPJQkjcMf6mSpHNZNehJNgN3AK8HdgN7kuw+a7NfAe6qqiuBG4DfGvZCJUnnNsgR+lXA4ap6oqqeBu4Erj9rmwK+tf/5VuBLw1uiJGkQgwT9UuD4kvsn+mNL3QK8JckJ4CDwjuWeKMlskoUkC4uLiy9guZKklQzrouge4ONVtQN4A/AHSZ733FU1V1XTVTW9ffv2IU0tSYLBgv4kcNmS+zv6Y0u9FbgLoKr+AXgRsG0YC5QkDWaQoN8P7EpyeZKL6V30PHDWNseAawCSfA+9oHtORZLGaNWgV9WzwE3AIeAxeu9meSTJrUmu62/2buBtSf4R+CTw09XVv5whSRvUQL8+t6oO0rvYuXTsvUs+fxS4erhLkySdD39SVJIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREDBT3JtUkeT3I4yc0rbPPmJI8meSTJHw53mZKk1WxZbYMkm4E7gB8FTgD3JzlQVY8u2WYX8B7g6qr6epJvH9WCJUnLG+QI/SrgcFU9UVVPA3cC15+1zduAO6rq6wBV9dRwlylJWs0gQb8UOL7k/on+2FKvAF6R5O+TfCbJtcs9UZLZJAtJFhYXF1/YiiVJyxrWRdEtwC7gtcAe4CNJXnr2RlU1V1XTVTW9ffv2IU0tSYLBgv4kcNmS+zv6Y0udAA5U1TNV9UXgn+kFXpI0JoME/X5gV5LLk1wM3AAcOGubP6F3dE6SbfROwTwxxHVKklaxatCr6lngJuAQ8BhwV1U9kuTWJNf1NzsEfC3Jo8B9wC9W1ddGtWhJ0vOlqjqZeHp6uhYWFjqZW5LWqyQPVNX0co/5k6KS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNGCjoSa5N8niSw0luPsd2P5mkkkwPb4mSpEGsGvQkm4E7gNcDu4E9SXYvs91LgHcCnx32IiVJqxvkCP0q4HBVPVFVTwN3Atcvs92vAr8O/PcQ1ydJGtAgQb8UOL7k/on+2P9J8irgsqr683M9UZLZJAtJFhYXF897sZKklV3wRdEkm4APAe9ebduqmquq6aqa3r59+4VOLUlaYpCgPwlctuT+jv7YaS8BXgn8bZIjwGuAA14YlaTxGiTo9wO7klye5GLgBuDA6Qer6mRVbauqqaqaAj4DXFdVCyNZsSRpWasGvaqeBW4CDgGPAXdV1SNJbk1y3agXKEkazJZBNqqqg8DBs8beu8K2r73wZUmSzpc/KSpJjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktSIgYKe5Nokjyc5nOTmZR7/hSSPJnkoyb1JJoe/VEnSuawa9CSbgTuA1wO7gT1Jdp+12YPAdFV9L3A38BvDXqgk6dwGOUK/CjhcVU9U1dPAncD1Szeoqvuq6lT/7meAHcNdpiRpNYME/VLg+JL7J/pjK3kr8BfLPZBkNslCkoXFxcXBVylJWtVQL4omeQswDXxwuceraq6qpqtqevv27cOcWpI2vC0DbPMkcNmS+zv6Y2dI8jpgL/DDVfU/w1meJGlQgxyh3w/sSnJ5kouBG4ADSzdIciXwu8B1VfXU8JcpSVrNqkGvqmeBm4BDwGPAXVX1SJJbk1zX3+yDwIuBP0ry+SQHVng6SdKIDHLKhao6CBw8a+y9Sz5/3ZDXJUk6T/6kqCQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiPWV9Dn52FqCjZt6t3Oz3e9IklaM7Z0vYCBzc/D7CycOtW7f/Ro7z7AzEx365KkNWL9HKHv3fv/MT/t1KneuCRpHQX92LHzG5ekDWb9BH3nzvMbl6QNZv0Efd8+mJg4c2xiojcuSVpHQZ+Zgbk5mJyEpHc7N+cFUUnqWz/vcoFevA24JC1r/RyhS5LOyaBLUiMMuiQ1wqBLUiMMuiQ1IlXVzcTJInD0Bf7n24CvDnE564H7vDG4zxvDhezzZFVtX+6BzoJ+IZIsVNV01+sYJ/d5Y3CfN4ZR7bOnXCSpEQZdkhqxXoM+1/UCOuA+bwzu88Ywkn1el+fQJUnPt16P0CVJZzHoktSIdRf0JNcmeTzJ4SQ3d72eUUtyWZL7kjya5JEk7+x6TeOQZHOSB5P8WddrGYckL01yd5J/SvJYku/vek2jluTn+1/TX0jyySQv6npNw5bkY0meSvKFJWPfluSvk/xL//Zlw5pvXQU9yWbgDuD1wG5gT5Ld3a5q5J4F3l1Vu4HXAD+7AfYZ4J3AY10vYow+DPxlVX038H00vu9JLgV+DpiuqlcCm4Ebul3VSHwcuPassZuBe6tqF3Bv//5QrKugA1cBh6vqiap6GrgTuL7jNY1UVX25qj7X//w/6f1Fv7TbVY1Wkh3AjwEf7Xot45BkK/BDwO8BVNXTVfXv3a5qLLYA35JkCzABfKnj9QxdVf0d8G9nDV8PfKL/+SeAnxjWfOst6JcCx5fcP0HjcVsqyRRwJfDZblcycrcDvwQ81/VCxuRyYBH4/f5ppo8muaTrRY1SVT0J/CZwDPgycLKq/qrbVY3Ny6vqy/3PvwK8fFhPvN6CvmEleTHwx8C7quo/ul7PqCT5ceCpqnqg67WM0RbgVcBvV9WVwH8xxJfha1H/vPH19L6ZfSdwSZK3dLuq8ave+8aH9t7x9Rb0J4HLltzf0R9rWpKL6MV8vqo+1fV6Ruxq4LokR+idUvuRJPu7XdLInQBOVNXpV1530wt8y14HfLGqFqvqGeBTwA90vKZx+dck3wHQv31qWE+83oJ+P7AryeVJLqZ3EeVAx2saqSShd271sar6UNfrGbWqek9V7aiqKXp/vn9TVU0fuVXVV4DjSb6rP3QN8GiHSxqHY8Brkkz0v8avofELwUscAG7sf34j8KfDeuJ19Y9EV9WzSW4CDtG7Kv6xqnqk42WN2tXATwEPJ/l8f+yXq+pgh2vS8L0DmO8fqDwB/EzH6xmpqvpskruBz9F7J9eDNPgrAJJ8EngtsC3JCeB9wK8BdyV5K71fIf7moc3nj/5LUhvW2ykXSdIKDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1Ij/hcAI7OrBgMXYgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "NUM_EPOCHS = 10\n",
        "opti = tf.keras.optimizers.SGD(learning_rate = 0.1)\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
        "val_accuracy = tf.keras.metrics.CategoricalAccuracy(name='val_accuracy')\n",
        "\n",
        "train_loss.reset_states()\n",
        "train_accuracy.reset_states()\n",
        "val_loss.reset_states()\n",
        "val_accuracy.reset_states()\n",
        "\n",
        "mlp_on_default = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output)\n",
        "\n",
        "valid_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(X_val.shape[0])\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=seed).batch(batch_size)\n",
        "train_ds_all = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(X_train.shape[0])\n",
        "\n",
        "for inputs, outputs in valid_ds:\n",
        "  preds = mlp_on_default.forward(inputs, False)\n",
        "  val_loss(mlp_on_default.loss(preds,outputs))\n",
        "  val_accuracy(outputs, preds)\n",
        "\n",
        "print(\n",
        "  f'Epoch {0}, \\n '\n",
        "  f'Val Loss: {val_loss.result()}, '\n",
        "  f'Val Accuracy: {val_accuracy.result() * 100}'\n",
        ")\n",
        "plt.plot(0, val_accuracy.result(), 'ro-',label=\"Validate accuracy\")\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  val_loss.reset_states()\n",
        "  val_accuracy.reset_states()\n",
        "\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*seed).batch(batch_size)\n",
        "  \n",
        "  for inputs, outputs in train_ds:\n",
        "    mlp_on_default.backward(inputs, outputs,opti)\n",
        "  for inputs, outputs in train_ds_all:\n",
        "    mlp_on_default.BNLayer(inputs)\n",
        "  #print(mlp_on_default.variables_untraining[0])\n",
        "\n",
        "  for inputs, outputs in train_ds_all:\n",
        "    preds = mlp_on_default.forward(inputs, False)\n",
        "    train_loss(mlp_on_default.loss(preds,outputs))\n",
        "    train_accuracy(outputs, preds)\n",
        "\n",
        "  for inputs, outputs in valid_ds:\n",
        "    preds = mlp_on_default.forward(inputs, False)\n",
        "    val_loss(mlp_on_default.loss(preds,outputs))\n",
        "    val_accuracy(outputs, preds)\n",
        "  \n",
        "  print(\n",
        "    f'Epoch {epoch + 1}, \\n'\n",
        "    f'Loss: {train_loss.result()}, '\n",
        "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
        "    f'Val loss: {val_loss.result()}, '\n",
        "    f'Val Accuracy: {val_accuracy.result() * 100}'\n",
        "  )\n",
        "  plt.plot(epoch + 1, train_accuracy.result(), 'go-',label=\"Train accuracy\")\n",
        "  plt.plot(epoch + 1, val_accuracy.result(), 'ro-',label=\"Validate accuracy\")\n",
        "\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXEoRopzkARv",
        "outputId": "016e6e33-57d2-4717-d55d-23b7beb22aa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.3823568820953369, Test Accuracy: 87.29000091552734\n"
          ]
        }
      ],
      "source": [
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
        "\n",
        "test_loss.reset_states()\n",
        "test_accuracy.reset_states()\n",
        "\n",
        "train_ds_all = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(X_train.shape[0])\n",
        "for inputs, outputs in train_ds_all:\n",
        "  mlp_on_default.BNLayer(inputs)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(X_test.shape[0])\n",
        "\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_default.forward(inputs,False)\n",
        "  test_loss(mlp_on_default.loss(preds,outputs))\n",
        "  test_accuracy(outputs, preds)\n",
        "\n",
        "print(\n",
        "  f'Test Loss: {test_loss.result()}, '\n",
        "  f'Test Accuracy: {test_accuracy.result() * 100}'\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Post_Act_MLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}