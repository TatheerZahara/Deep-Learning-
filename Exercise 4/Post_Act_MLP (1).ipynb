{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_iYcla4kCX67"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "seed=5184\n",
        "np.random.seed(5184)\n",
        "tf.random.set_seed(5184)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgna3kY6CX67",
        "outputId": "2c48c036-3ae4-4e46-ca61-9f1ac48b5e11"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "tf.executing_eagerly()\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "JodgHy9nCX68",
        "outputId": "500a932c-7e4a-4d92-f082-c28548ab63d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data() # Load MNIST or FMNIST\n",
        "assert X_train.shape == (60000, 28, 28)\n",
        "assert X_test.shape == (10000, 28, 28)\n",
        "assert y_train.shape == (60000,)\n",
        "assert y_test.shape == (10000,)\n",
        "\n",
        "\n",
        "indices = list(np.random.randint(X_train.shape[0],size=3))\n",
        "for i in range(3):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(X_train[indices[i]].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.title(\"Index {} Class {}\".format(indices[i], y_train[indices[i]]))\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIRI-uLoCX69",
        "outputId": "2c14ac20-63f0-48af-f877-a5388c6095e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of training set is 50000 samples\n",
            "every train example is 28 by 28\n",
            "size of validation set is 10000 samples\n",
            "every validation example is 28 by 28\n",
            "size of training set is 50000 samples\n",
            "every train example has 784 features\n",
            "size of validation set is 10000 samples\n",
            "every validation example has 784 features\n"
          ]
        }
      ],
      "source": [
        "# Split train dataset into train and validation\n",
        "X_val = X_train[50000:60000]\n",
        "X_train = X_train[0:50000]\n",
        "y_val = y_train[50000:60000]\n",
        "y_train = y_train[0:50000]\n",
        "\n",
        "print(\"size of training set is\", str(X_train.shape[0]), \"samples\")\n",
        "print(\"every train example is\", str(X_train.shape[1]), \"by\", str(X_train.shape[2]))\n",
        "\n",
        "print(\"size of validation set is\", str(X_val.shape[0]), \"samples\")\n",
        "print(\"every validation example is\", str(X_val.shape[1]), \"by\", str(X_val.shape[2]))\n",
        "\n",
        "X_train = X_train.reshape(50000, 28*28)\n",
        "X_val = X_val.reshape(10000, 28*28)\n",
        "X_test = X_test.reshape(10000, 28*28)\n",
        "\n",
        "print(\"size of training set is\", str(X_train.shape[0]), \"samples\")\n",
        "print(\"every train example has\", str(X_train.shape[1]), \"features\")\n",
        "\n",
        "print(\"size of validation set is\", str(X_val.shape[0]), \"samples\")\n",
        "print(\"every validation example has\", str(X_val.shape[1]), \"features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDyZ8bZjCX69",
        "outputId": "cb315ac1-a65a-4d8a-843a-339435af093a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#Normalize Data\n",
        "\n",
        "X_train = X_train/255.0\n",
        "X_val = X_val/255.0\n",
        "X_test = X_test/255.0\n",
        "# X_train[0]\n",
        "np.max(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lIIy313CX69",
        "outputId": "6e68d5c8-cf5f-4e0a-a42e-87b02e77097a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10000], shape=(1,), dtype=int32)\n",
            "tf.Tensor([10000    10], shape=(2,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "size_input = X_train.shape[1]\n",
        "size_hidden1 = 128\n",
        "size_hidden2 = 128\n",
        "size_hidden3 = 128\n",
        "size_output = 10\n",
        "\n",
        "batch_size=128\n",
        "lr=0.1\n",
        "\n",
        "number_of_train_examples = X_train.shape[0]\n",
        "number_of_test_examples = X_test.shape[0]\n",
        "\n",
        "print(tf.shape(y_val))\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10) # Other function is tf.one_hot(y_train,depth=10)\n",
        "y_val = tf.keras.utils.to_categorical(y_val, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "print(tf.shape(y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "obN7WPLpCX69"
      },
      "outputs": [],
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device=None):\n",
        "    self.size_input, self.size_hidden1, self.size_hidden2, self.size_hidden3, self.size_output, self.device =\\\n",
        "    size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device\n",
        "\n",
        "    self.initial=tf.keras.initializers.he_normal(seed=seed)\n",
        "    \n",
        "    # Initialize weights between input mapping and a layer g(f(x)) = layer\n",
        "    self.W1 = tf.Variable(self.initial([self.size_input, self.size_hidden1])) # Xavier(Fan-in fan-out) and Orthogonal\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b1 = tf.Variable(tf.zeros([1, self.size_hidden1])) # 0 or constant(0.01)\n",
        "    \n",
        "    # Initialize weights between input layer and 1st hidden layer\n",
        "    self.W2 = tf.Variable(self.initial([self.size_hidden1, self.size_hidden2]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b2 = tf.Variable(tf.zeros([1, self.size_hidden2]))\n",
        "    \n",
        "    # Initialize weights between 1st hidden layer and 2nd hidden layer\n",
        "    self.W3 = tf.Variable(self.initial([self.size_hidden2, self.size_hidden3]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b3 = tf.Variable(tf.zeros([1, self.size_hidden3]))\n",
        "    \n",
        "     # Initialize weights between 2nd hidden layer and output layer\n",
        "    self.W4 = tf.Variable(self.initial([self.size_hidden3, self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b4 = tf.Variable(tf.zeros([1, self.size_output]))\n",
        "\n",
        "    self.gamma1=tf.Variable(tf.ones([1, self.size_hidden1]))\n",
        "    self.beta1=tf.Variable(tf.zeros([1, self.size_hidden1]))\n",
        "\n",
        "    self.gamma2=tf.Variable(tf.ones([1, self.size_hidden2]))\n",
        "    self.beta2=tf.Variable(tf.zeros([1, self.size_hidden2]))\n",
        "\n",
        "    self.gamma3=tf.Variable(tf.ones([1, self.size_hidden3]))\n",
        "    self.beta3=tf.Variable(tf.zeros([1, self.size_hidden3]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.W4, self.b1, self.b2, self.b3, self.b4, self.gamma1, self.beta1, self.gamma2, self.beta2, self.gamma3, self.beta3]\n",
        "\n",
        "    self.mean1=tf.Variable(tf.zeros([1, self.size_hidden1]))\n",
        "    self.var1=tf.Variable(tf.ones([1, self.size_hidden1]))\n",
        "    self.mean2=tf.Variable(tf.zeros([1, self.size_hidden2]))\n",
        "    self.var2=tf.Variable(tf.ones([1, self.size_hidden2]))\n",
        "    self.mean3=tf.Variable(tf.zeros([1, self.size_hidden3]))\n",
        "    self.var3=tf.Variable(tf.ones([1, self.size_hidden3]))\n",
        "\n",
        "    self.variables_untraining = [self.mean1, self.var1, self.mean2, self.var2, self.mean3, self.var3]\n",
        "\n",
        "    self.epsilon=0.001\n",
        "\n",
        "    #self.untrain_variables=[]\n",
        "  \n",
        "  def forward(self, X, training):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X, training)\n",
        "    else:\n",
        "      self.y = self.compute_output(X, training)\n",
        "      \n",
        "    return self.y\n",
        "\n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    #y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_true_tf = tf.cast(y_true, dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    loss_x = cce(y_true_tf, y_pred_tf)\n",
        "    \n",
        "    return loss_x\n",
        "\n",
        "  def backward(self, X_train, y_train, opti):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = opti\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "        \n",
        "      predicted = self.forward(X_train, True)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "        \n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "           \n",
        "  def compute_output(self, X, training):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    if training==True:\n",
        "      # Cast X to float32\n",
        "      X_tf = tf.cast(X, dtype=tf.float32)\n",
        "      #X_tf = X\n",
        "      \n",
        "      # Compute values in hidden layers\n",
        "      z1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "      h1 = tf.nn.relu(z1)\n",
        "      mean1=tf.math.reduce_mean(h1, 0)\n",
        "      var1=tf.math.reduce_variance(h1, 0)\n",
        "      h1 = (h1-mean1)/tf.math.sqrt(var1+self.epsilon)*self.gamma1+self.beta1\n",
        "      \n",
        "      z2 = tf.matmul(h1, self.W2) + self.b2\n",
        "      h2 = tf.nn.relu(z2)\n",
        "      mean2=tf.math.reduce_mean(h2, 0)\n",
        "      var2=tf.math.reduce_variance(h2, 0)\n",
        "      h2 = (h2-mean2)/tf.math.sqrt(var2+self.epsilon)*self.gamma2+self.beta2\n",
        "      \n",
        "      z3 = tf.matmul(h2, self.W3) + self.b3\n",
        "      h3 = tf.nn.relu(z3)\n",
        "      mean3=tf.math.reduce_mean(h3, 0)\n",
        "      var3=tf.math.reduce_variance(h3, 0)\n",
        "      h3 = (h3-mean3)/tf.math.sqrt(var3+self.epsilon)*self.gamma3+self.beta3\n",
        "\n",
        "      # Compute output\n",
        "      output = tf.matmul(h3, self.W4) + self.b4\n",
        "      \n",
        "      #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this \n",
        "      # Second add tf.Softmax(output) and then return this variable\n",
        "    elif training==False:\n",
        "      # Cast X to float32\n",
        "      X_tf = tf.cast(X, dtype=tf.float32)\n",
        "      #X_tf = X\n",
        "      \n",
        "      # Compute values in hidden layers\n",
        "      z1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "      h1 = tf.nn.relu(z1)\n",
        "      mean1=self.mean1\n",
        "      var1=self.var1\n",
        "      h1 = (h1-mean1)/tf.math.sqrt(var1+self.epsilon)*self.gamma1+self.beta1\n",
        "      \n",
        "      z2 = tf.matmul(h1, self.W2) + self.b2\n",
        "      h2 = tf.nn.relu(z2)\n",
        "      mean2=self.mean2\n",
        "      var2=self.var2\n",
        "      h2 = (h2-mean2)/tf.math.sqrt(var2+self.epsilon)*self.gamma2+self.beta2\n",
        "      \n",
        "      z3 = tf.matmul(h2, self.W3) + self.b3\n",
        "      h3 = tf.nn.relu(z3)\n",
        "      mean3=self.mean3\n",
        "      var3=self.var3\n",
        "      h3 = (h3-mean3)/tf.math.sqrt(var3+self.epsilon)*self.gamma3+self.beta3\n",
        "\n",
        "      # Compute output\n",
        "      output = tf.matmul(h3, self.W4) + self.b4\n",
        "\n",
        "    return (output)\n",
        "\n",
        "  def BNLayer(self, X):\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #X_tf = X\n",
        "    \n",
        "    # Compute values in hidden layers\n",
        "    z1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    h1 = tf.nn.relu(z1)\n",
        "    self.mean1=tf.math.reduce_mean(h1, 0)\n",
        "    self.var1=tf.math.reduce_variance(h1, 0)\n",
        "    h1 = (h1-self.mean1)/tf.math.sqrt(self.var1+self.epsilon)*self.gamma1+self.beta1\n",
        "    \n",
        "    z2 = tf.matmul(h1, self.W2) + self.b2\n",
        "    h2 = tf.nn.relu(z2)\n",
        "    self.mean2=tf.math.reduce_mean(h2, 0)\n",
        "    self.var2=tf.math.reduce_variance(h2, 0)\n",
        "    h2 = (h2-self.mean2)/tf.math.sqrt(self.var2+self.epsilon)*self.gamma2+self.beta2\n",
        "    \n",
        "    z3 = tf.matmul(h2, self.W3) + self.b3\n",
        "    h3 = tf.nn.relu(z3)\n",
        "    self.mean3=tf.math.reduce_mean(h3, 0)\n",
        "    self.var3=tf.math.reduce_variance(h3, 0)\n",
        "    h3 = (h3-self.mean3)/tf.math.sqrt(self.var3+self.epsilon)*self.gamma3+self.beta3\n",
        "    \n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "id": "hJUoVOzAkARt",
        "outputId": "0ffacdea-75a5-497c-b00e-9d113bb12887"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: \n",
            " Val Loss: 2.406646490097046, Val Accuracy: 9.5600004196167\n",
            "Epoch 1: \n",
            "Loss: 0.3566393256187439, Accuracy: 87.01200103759766, Validation Loss: 0.39560219645500183, Validation Accuracy: 85.5999984741211\n",
            "Epoch 2: \n",
            "Loss: 0.3128078579902649, Accuracy: 88.39399719238281, Validation Loss: 0.3627564609050751, Validation Accuracy: 86.36000061035156\n",
            "Epoch 3: \n",
            "Loss: 0.2825682461261749, Accuracy: 89.71800231933594, Validation Loss: 0.34797191619873047, Validation Accuracy: 87.19999694824219\n",
            "Epoch 4: \n",
            "Loss: 0.2680355906486511, Accuracy: 90.11599731445312, Validation Loss: 0.34061527252197266, Validation Accuracy: 87.37999725341797\n",
            "Epoch 5: \n",
            "Loss: 0.25107336044311523, Accuracy: 90.86599731445312, Validation Loss: 0.34139198064804077, Validation Accuracy: 87.80000305175781\n",
            "Epoch 6: \n",
            "Loss: 0.23138123750686646, Accuracy: 91.47599792480469, Validation Loss: 0.33413583040237427, Validation Accuracy: 87.91000366210938\n",
            "Epoch 7: \n",
            "Loss: 0.22537674009799957, Accuracy: 91.74800109863281, Validation Loss: 0.3374636769294739, Validation Accuracy: 87.86000061035156\n",
            "Epoch 8: \n",
            "Loss: 0.2188052386045456, Accuracy: 91.93000030517578, Validation Loss: 0.34468626976013184, Validation Accuracy: 87.55999755859375\n",
            "Epoch 9: \n",
            "Loss: 0.21490849554538727, Accuracy: 92.01599884033203, Validation Loss: 0.3519841432571411, Validation Accuracy: 87.80000305175781\n",
            "Epoch 10: \n",
            "Loss: 0.20495323836803436, Accuracy: 92.33200073242188, Validation Loss: 0.3604591190814972, Validation Accuracy: 87.87000274658203\n",
            "\n",
            "Total time taken (in seconds): 129.57\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "NUM_EPOCHS = 10\n",
        "opti = tf.keras.optimizers.SGD(learning_rate = 0.1)\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
        "val_accuracy = tf.keras.metrics.CategoricalAccuracy(name='val_accuracy')\n",
        "\n",
        "train_loss.reset_states()\n",
        "train_accuracy.reset_states()\n",
        "val_loss.reset_states()\n",
        "val_accuracy.reset_states()\n",
        "\n",
        "mlp_on_default = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output)\n",
        "\n",
        "valid_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(X_val.shape[0])\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=seed).batch(batch_size)\n",
        "train_ds_all = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(X_train.shape[0])\n",
        "\n",
        "for inputs, outputs in valid_ds:\n",
        "  preds = mlp_on_default.forward(inputs, False)\n",
        "  val_loss(mlp_on_default.loss(preds,outputs))\n",
        "  val_accuracy(outputs, preds)\n",
        "\n",
        "print(\n",
        "  f'Epoch {0}: \\n '\n",
        "  f'Val Loss: {val_loss.result()}, '\n",
        "  f'Val Accuracy: {val_accuracy.result() * 100}'\n",
        ")\n",
        "plt.plot(0, val_accuracy.result(), 'ro-',label=\"Validate accuracy\")\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  val_loss.reset_states()\n",
        "  val_accuracy.reset_states()\n",
        "\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*seed).batch(batch_size)\n",
        "  \n",
        "  for inputs, outputs in train_ds:\n",
        "    mlp_on_default.backward(inputs, outputs,opti)\n",
        "  for inputs, outputs in train_ds_all:\n",
        "    mlp_on_default.BNLayer(inputs)\n",
        "  #print(mlp_on_default.variables_untraining[0])\n",
        "\n",
        "  for inputs, outputs in train_ds_all:\n",
        "    preds = mlp_on_default.forward(inputs, False)\n",
        "    train_loss(mlp_on_default.loss(preds,outputs))\n",
        "    train_accuracy(outputs, preds)\n",
        "\n",
        "  for inputs, outputs in valid_ds:\n",
        "    preds = mlp_on_default.forward(inputs, False)\n",
        "    val_loss(mlp_on_default.loss(preds,outputs))\n",
        "    val_accuracy(outputs, preds)\n",
        "  \n",
        "  print(\n",
        "    f'Epoch {epoch + 1}: \\n'\n",
        "    f'Loss: {train_loss.result()}, '\n",
        "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
        "    f'Validation Loss: {val_loss.result()}, '\n",
        "    f'Validation Accuracy: {val_accuracy.result() * 100}'\n",
        "  )\n",
        "  plt.plot(epoch + 1, train_accuracy.result(), 'go-',label=\"Train accuracy\")\n",
        "  plt.plot(epoch + 1, val_accuracy.result(), 'ro-',label=\"Validate accuracy\")\n",
        "\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXEoRopzkARv",
        "outputId": "7d4896c3-6ba3-435e-8f7d-4c9e0a754f19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.37356001138687134, Test Accuracy: 87.19000244140625\n"
          ]
        }
      ],
      "source": [
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
        "\n",
        "test_loss.reset_states()\n",
        "test_accuracy.reset_states()\n",
        "\n",
        "train_ds_all = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(X_train.shape[0])\n",
        "for inputs, outputs in train_ds_all:\n",
        "  mlp_on_default.BNLayer(inputs)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(X_test.shape[0])\n",
        "\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_default.forward(inputs,False)\n",
        "  test_loss(mlp_on_default.loss(preds,outputs))\n",
        "  test_accuracy(outputs, preds)\n",
        "\n",
        "print(\n",
        "  f'Test Loss: {test_loss.result()}, '\n",
        "  f'Test Accuracy: {test_accuracy.result() * 100}'\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Post_Act_MLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}